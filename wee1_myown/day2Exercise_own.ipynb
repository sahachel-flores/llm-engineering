{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"model\": MODEL,\n",
    "    \"message\": messages,\n",
    "    \"stream\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "# !ollama pull llama3.2\n",
    "\n",
    "\n",
    "# Making API call using requests library (did not work for me, I had to use ollama library)\n",
    "\n",
    "#response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "#print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI can generate high-quality content such as blog posts, social media posts, product descriptions, and more. This can help businesses streamline their content creation process, reduce costs, and increase efficiency.\n",
      "2. **Image and Video Generation**: Generative AI can create realistic images and videos that can be used for marketing, advertising, and entertainment purposes. For example, AI-generated avatars can be used in virtual reality (VR) and augmented reality (AR) applications.\n",
      "3. **Product Design and Development**: Generative AI can help designers and engineers generate new product ideas, designs, and prototypes more quickly and efficiently than traditional methods.\n",
      "4. **Marketing Automation**: AI-powered generative models can analyze customer data and behavior to create personalized marketing campaigns, such as emails, ads, and social media posts.\n",
      "5. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants that can understand natural language and generate human-like responses to customer inquiries.\n",
      "6. **Music and Audio Generation**: AI can generate music, sound effects, and audio tracks for various applications, such as video games, films, and advertising.\n",
      "7. **Data Analysis and Visualization**: Generative AI can help analyze and visualize large datasets, making it easier for businesses to gain insights and make data-driven decisions.\n",
      "8. **Financial Modeling and Forecasting**: AI-powered generative models can create financial models, forecasts, and predictions that can help businesses anticipate market trends and make more informed investment decisions.\n",
      "9. **Customer Experience**: Generative AI can analyze customer feedback and sentiment analysis to generate personalized responses, offers, and experiences that improve customer satisfaction.\n",
      "10. **Supply Chain Optimization**: AI-powered generative models can optimize supply chain operations by predicting demand, managing inventory, and identifying potential bottlenecks.\n",
      "\n",
      "Some specific business use cases of Generative AI include:\n",
      "\n",
      "* **Automated content creation for news organizations**, where AI-generated articles can help reduce costs and increase efficiency.\n",
      "* **Personalized product recommendations for e-commerce platforms**, where AI-powered generative models can analyze customer behavior and preferences to suggest relevant products.\n",
      "* **Virtual event planning and management**, where AI can generate realistic avatars, environments, and experiences for virtual events.\n",
      "* **Automated data annotation and labeling**, where AI-generated labels can help improve machine learning model accuracy.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# alternative way of calling llamas3.2, using ollama python library\n",
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "------------------------------------------------------------------------------\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "Navigation\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1 for sys_prompt\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2 for sys_prompt\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_for(ed)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Website Summary\n",
      "\n",
      "#### Overview\n",
      "The website is centered around Edward Donner, a co-founder and CTO of Nebula.io, an AI startup that applies artificial intelligence to help people discover their potential.\n",
      "\n",
      "#### Content\n",
      "- The website features an \"Outsmart\" arena where LLMs (Large Language Models) engage in battles of diplomacy and deviousness.\n",
      "- There is no detailed content about the Outsmart arena on this page, so it's unclear how it functions or what the outcomes are.\n",
      "- Edward Donner shares his personal interests in coding, DJing, and amateur electronic music production.\n",
      "- He briefly discusses his background as the co-founder and CEO of AI startup untapt, which was acquired in 2021.\n",
      "\n",
      "#### News/Announcements\n",
      "- **December 21, 2024**: A workshop on LLMs called \"LLM Workshop – Hands-on with Agents\" is scheduled.\n",
      "- **November 13, 2024**: An announcement for \"Welcome, SuperDataScientists!\" seems to be a welcoming message, but no further details are provided.\n",
      "- **October 16, 2024**: Resources for mastering AI and LLM engineering have been published.\n",
      "- **October 16, 2024**: Resources for transitioning from software engineer to AI data scientist have also been published.\n",
      "\n",
      "#### Links\n",
      "- A contact email is available (ed [at] edwarddonner [dot] com).\n",
      "- A website URL and social media profiles are listed.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
