{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain, plotly and Chroma\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price is a factor for our company, so we're going to use a low cost model\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] =  os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 123\n",
      "Document types found: {'contracts', 'employees', 'company', 'products'}\n"
     ]
    }
   ],
   "source": [
    "# Read in documents using LangChain's loaders\n",
    "# Take everything in all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"knowledge-base/*\")\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "# With thanks to CG and Jon R, students on the course, for this fix needed for some users\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "# If that doesn't work, some Windows users might need to uncomment the next line instead\n",
    "# text_loader_kwargs={'autodetect_encoding': True}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 123 documents\n"
     ]
    }
   ],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then replace embeddings = OpenAIEmbeddings()\n",
    "# with:\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 123 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/pt6sv1dj0dn30_gqycp659z80000gn/T/ipykernel_3736/1174663558.py:8: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Alternative - if you'd like to use Ollama locally, uncomment this line instead\n",
    "# llm = ChatOpenAI(temperature=0.7, model_name='llama3.2', base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping that in a function\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# And in Gradio:\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "- **2022**: **Satisfactory**  \n",
      "  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \n",
      "\n",
      "- **2023**: **Exceeds Expectations**  \n",
      "  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:**  \n",
      "  - Completed onboarding successfully.  \n",
      "  - Met expectations in delivering project milestones.  \n",
      "  - Received positive feedback from the team leads.\n",
      "\n",
      "- **2021:**  \n",
      "  - Achieved a 95% success rate in project delivery timelines.  \n",
      "  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \n",
      "\n",
      "- **2022:**  \n",
      "  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \n",
      "  - Conducted training sessions for junior developers, fostering knowledge sharing.  \n",
      "\n",
      "- **2023:**  \n",
      "  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \n",
      "  - Contributed to the company’s transition to a cloud-based infrastructure.  \n",
      "  - Received an overall performance rating of 4.8/5.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2018**: **3/5** - Adaptable team player but still learning to take initiative.\n",
      "- **2019**: **4/5** - Demonstrated strong problem-solving skills, outstanding contribution on the claims project.\n",
      "- **2020**: **2/5** - Struggled with time management; fell behind on deadlines during a high-traffic release period.\n",
      "- **2021**: **4/5** - Made a significant turnaround with organized work habits and successful project management.\n",
      "- **2022**: **5/5** - Exceptional performance during the \"Innovate\" initiative, showcasing leadership and creativity.\n",
      "- **2023**: **3/5** - Maintaining steady work; expectations for innovation not fully met, leading to discussions about goals.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2023:** Rating: 4.5/5  \n",
      "  *Samuel exceeded expectations, successfully leading a cross-departmental project on AI-driven underwriting processes.*\n",
      "\n",
      "- **2022:** Rating: 3.0/5  \n",
      "  *Some challenges in meeting deadlines and collaboration with the engineering team. Received constructive feedback and participated in a team communication workshop.*\n",
      "\n",
      "- **2021:** Rating: 4.0/5  \n",
      "  *There was notable improvement in performance. Worked to enhance model accuracy, leading to improved risk assessment outcomes for B2C customers.*\n",
      "\n",
      "- **2020:** Rating: 3.5/5  \n",
      "  *Exhibited a solid performance during the initial year as a Senior Data Scientist but had struggles adapting to new leadership expectations.*\n",
      "\n",
      "## Compensation History\n",
      "- **2023:** Base Salary: $115,000 + Bonus: $15,000  \n",
      "  *Annual bonus based on successful project completions and performance metrics.*\n",
      "Human: Who received the prestigious IIOTY award in 2023?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Answer: I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate what gets sent behind the scenes\n",
    "\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Adding callbacks to our chain\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])\n",
    "\n",
    "# Adding our query question and getting traces back\n",
    "query = \"Who received the prestigious IIOTY award in 2023?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "- **2022**: **Satisfactory**  \n",
      "  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \n",
      "\n",
      "- **2023**: **Exceeds Expectations**  \n",
      "  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:**  \n",
      "  - Completed onboarding successfully.  \n",
      "  - Met expectations in delivering project milestones.  \n",
      "  - Received positive feedback from the team leads.\n",
      "\n",
      "- **2021:**  \n",
      "  - Achieved a 95% success rate in project delivery timelines.  \n",
      "  - Awarded \"Rising Star\" at the annual company gala for outstanding contributions.  \n",
      "\n",
      "- **2022:**  \n",
      "  - Exceeded goals by optimizing existing backend code, improving system performance by 25%.  \n",
      "  - Conducted training sessions for junior developers, fostering knowledge sharing.  \n",
      "\n",
      "- **2023:**  \n",
      "  - Led a major overhaul of the API internal architecture, enhancing security protocols.  \n",
      "  - Contributed to the company’s transition to a cloud-based infrastructure.  \n",
      "  - Received an overall performance rating of 4.8/5.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2018**: **3/5** - Adaptable team player but still learning to take initiative.\n",
      "- **2019**: **4/5** - Demonstrated strong problem-solving skills, outstanding contribution on the claims project.\n",
      "- **2020**: **2/5** - Struggled with time management; fell behind on deadlines during a high-traffic release period.\n",
      "- **2021**: **4/5** - Made a significant turnaround with organized work habits and successful project management.\n",
      "- **2022**: **5/5** - Exceptional performance during the \"Innovate\" initiative, showcasing leadership and creativity.\n",
      "- **2023**: **3/5** - Maintaining steady work; expectations for innovation not fully met, leading to discussions about goals.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2023:** Rating: 4.5/5  \n",
      "  *Samuel exceeded expectations, successfully leading a cross-departmental project on AI-driven underwriting processes.*\n",
      "\n",
      "- **2022:** Rating: 3.0/5  \n",
      "  *Some challenges in meeting deadlines and collaboration with the engineering team. Received constructive feedback and participated in a team communication workshop.*\n",
      "\n",
      "- **2021:** Rating: 4.0/5  \n",
      "  *There was notable improvement in performance. Worked to enhance model accuracy, leading to improved risk assessment outcomes for B2C customers.*\n",
      "\n",
      "- **2020:** Rating: 3.5/5  \n",
      "  *Exhibited a solid performance during the initial year as a Senior Data Scientist but had struggles adapting to new leadership expectations.*\n",
      "\n",
      "## Compensation History\n",
      "- **2023:** Base Salary: $115,000 + Bonus: $15,000  \n",
      "  *Annual bonus based on successful project completions and performance metrics.*\n",
      "\n",
      "## Annual Performance History\n",
      "- **2019:** Exceeds Expectations - Continuously delivered high-quality code and participated actively in team meetings.\n",
      "- **2020:** Meets Expectations - Jordan K. Bishop maintained steady performance but faced challenges due to a higher workload from multiple projects.\n",
      "- **2021:** Exceeds Expectations - Recognized for leadership during the customer portal project; received the “Innovation Award” for creative problem-solving.\n",
      "- **2022:** Meets Expectations - While mentoring others, the shift in focus led to fewer contributions to new features, marking a decrease in performance.\n",
      "- **2023:** Needs Improvement - Transitioning back to development has resulted in difficulties with recent technologies, prompting a performance improvement plan.\n",
      "\n",
      "- **2021**: *Exceeds Expectations*  \n",
      "  Maxine spearheaded the transition to a new data warehousing solution, significantly enhancing Insurellm’s data analytics capabilities. This major achievement bolstered her reputation within the company.  \n",
      "\n",
      "- **2022**: *Outstanding*  \n",
      "  Maxine continued her upward trajectory, successfully implementing machine learning algorithms to predict customer behavior, which was well-received by the leadership team and improved client satisfaction.  \n",
      "\n",
      "- **2023**: *Exceeds Expectations*  \n",
      "  Maxine has taken on mentoring responsibilities and is leading a cross-functional team for data governance initiatives, showcasing her leadership and solidifying her role at Insurellm.\n",
      "\n",
      "- **2018**: **Exceeds Expectations**  \n",
      "  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \n",
      "\n",
      "- **2019**: **Meets Expectations**  \n",
      "  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \n",
      "\n",
      "- **2020**: **Below Expectations**  \n",
      "  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \n",
      "\n",
      "- **2021**: **Exceptional**  \n",
      "  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \n",
      "\n",
      "- **2022**: **Satisfactory**  \n",
      "  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.\n",
      "\n",
      "- **January 2017 - May 2018**: Marketing Intern  \n",
      "  - Supported the Marketing team by collaborating on content creation and digital advertising projects.\n",
      "  - Gained hands-on experience with marketing automation tools, enriching her skillset for her role in Insurellm.\n",
      "\n",
      "---\n",
      "\n",
      "## Annual Performance History\n",
      "- **2023**:  \n",
      "  - Performance Rating: Exceeds Expectations  \n",
      "  - Key Achievements: Led the \"Tech the Halls\" campaign that resulted in a 50% increase in leads during the holiday season. \n",
      "  - Emily Tran's innovative strategies and attention to detail have made her stand out among her peers.\n",
      "\n",
      "- **2022**:  \n",
      "  - Performance Rating: Meets Expectations  \n",
      "  - Key Achievements: Enhanced Insurellm's email marketing strategy, achieving a 25% open rate increase.\n",
      "\n",
      "- **2021**:  \n",
      "  - Performance Rating: Meets Expectations  \n",
      "  - Key Achievements: Contributed to the launch of a customer referral program that resulted in a 15% growth in B2C customers.\n",
      "\n",
      "---\n",
      "\n",
      "## Annual Performance History  \n",
      "- **2022** - Rated as \"Exceeds Expectations.\" Alex Thomson achieved 150% of the sales target within the first three months.  \n",
      "- **2023** - Rated \"Outstanding.\" Recognized for innovative lead-generation tactics which contributed to a 30% increase in qualified leads for the sales team.  \n",
      "\n",
      "### Highlights:\n",
      "- Consistently maintained a 30-minute response time to inbound leads.\n",
      "- Successfully coordinated webinars for product launches, which attracted over 2,000 potential customers.\n",
      "\n",
      "## Compensation History\n",
      "- **2022**: Base Salary - $55,000 | Bonus - $5,000  \n",
      "- **2023**: Base Salary - $65,000 | Bonus - $10,000 (for exceeding sales targets and exceptional teamwork)  \n",
      "- **Projected for 2024**: Anticipated salary increase due to Alex Thomson's significant contributions and successful completion of leadership training.\n",
      "\n",
      "Join the growing number of organizations leveraging Rellm to enhance their reinsurance processes while driving profitability and compliance. \n",
      "\n",
      "## 2025-2026 Roadmap\n",
      "\n",
      "At Insurellm, we are committed to the continuous improvement of Rellm. Our roadmap for 2025-2026 includes:\n",
      "\n",
      "- **Q3 2025**: \n",
      "  - Launch of the Rellm Mobile App for on-the-go insights and management.\n",
      "  - Introduction of augmented reality (AR) features for interactive risk assessments.\n",
      "\n",
      "- **Q1 2026**: \n",
      "  - Deployment of advanced machine learning models for even more accurate risk predictions.\n",
      "  - Expansion of integration capabilities to support emerging technologies in the insurance sector.\n",
      "\n",
      "- **Q3 2026**: \n",
      "  - Release of a community platform for Rellm users to exchange insights, tips, and best practices.\n",
      "  - Launch of Rellm 2.0, featuring enhanced user interface and premium features based on user feedback.\n",
      "\n",
      "- **2010 - 2013**: Business Analyst at Edge Analytics  \n",
      "  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2015**: **Exceeds Expectations**  \n",
      "  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \n",
      "\n",
      "- **2016**: **Meets Expectations**  \n",
      "  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \n",
      "\n",
      "- **2017**: **Developing**  \n",
      "  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \n",
      "\n",
      "- **2018**: **Exceeds Expectations**  \n",
      "  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.\n",
      "\n",
      "All tiers include a comprehensive training program and ongoing updates to ensure optimal performance.\n",
      "\n",
      "## Roadmap\n",
      "The development roadmap for Homellm includes the following key milestones:\n",
      "\n",
      "- **Q1 2024:** Launch of Homellm version 1.0, featuring core functionalities and integrations.\n",
      "- **Q3 2024:** Introduction of enhanced analytics capabilities, including visualization tools and advanced reporting features.\n",
      "- **Q1 2025:** Release of Homellm version 2.0, with expanded predictive maintenance alerts and automated underwriting processes.\n",
      "- **Q3 2025:** Establish partnerships with IoT device manufacturers to provide integrated solutions for proactive risk management.\n",
      "- **Q1 2026:** Ongoing improvements based on user feedback and industry trends, ensuring that Homellm remains at the forefront of home insurance technology.\n",
      "\n",
      "## Compensation History\n",
      "- **March 2018**: Initial salary of $80,000.\n",
      "- **July 2019**: Salary increased to $90,000 post-promotion.\n",
      "- **June 2021**: Salary raised to $105,000 after role transition.\n",
      "- **September 2022**: Salary adjustment to $120,000 due to increased responsibilities and performance.\n",
      "- **January 2023**: Revised salary of $125,000 in recognition of mentorship role.\n",
      "\n",
      "## Other HR Notes\n",
      "- Oliver enjoys a strong rapport with team members and is known for organizing regular team-building activities.\n",
      "- Participated in Insurellm’s Hackathon in 2022, where he led a project that won “Best Overall Solution.” \n",
      "- Pursuing AWS Certified Solutions Architect certification to enhance cloud skillset.\n",
      "- Has expressed interest in further leadership opportunities within Insurellm and may consider project management roles in the future.\n",
      "\n",
      "- **2017-2019:** Marketing Intern  \n",
      "  - Assisted with market research and campaign development for social media outreach.  \n",
      "  - Achievements:  \n",
      "    - Contributed ideas for a social media campaign that increased brand awareness by 40% within 6 months.  \n",
      "\n",
      "## Annual Performance History\n",
      "| Year | Performance Rating | Key Highlights |\n",
      "|------|--------------------|----------------|\n",
      "| 2023 | 4.8/5              | Recognized for exceptional client feedback and teamwork during product launches. |\n",
      "| 2022 | 4.5/5              | Led a successful cross-selling initiative that boosted revenue in existing accounts. |\n",
      "| 2021 | 4.2/5              | Successfully onboarded new clients and established strong relationships that resulted in renewals. |\n",
      "\n",
      "Alex Chen continues to be a vital asset at Insurellm, contributing significantly to innovative backend solutions that help shape the future of insurance technology.\n",
      "\n",
      "### Q2 2025: Customer Experience Improvements\n",
      "- Launch of a new **mobile app** for end-users.\n",
      "- Introduction of **telematics-based pricing** to provide even more tailored coverage options.\n",
      "\n",
      "### Q3 2025: Global Expansion\n",
      "- Begin pilot programs for international insurance markets.\n",
      "- Collaborate with local insurers to offer compliant, localized versions of Carllm.\n",
      "\n",
      "### Q4 2025: AI and Machine Learning Upgrades\n",
      "- Implement next-gen machine learning models for predictive analysis.\n",
      "- Roll out customer insights dashboard updates based on user feedback.\n",
      "\n",
      "### 2026: Scaling and Partnerships\n",
      "- Increase partnerships with automakers for integrated insurance solutions.\n",
      "- Enhance the **AI customer support system** to include multi-language support.\n",
      "\n",
      "Carllm is not just an auto insurance product; it is a transformative tool for the insurance industry. Join us on this exciting journey as we redefine the future of auto insurance with technology and customer-centric solutions.\n",
      "\n",
      "**TechDrive Insurance Representative:**  \n",
      "Name: Sarah Johnson  \n",
      "Title: Operations Director  \n",
      "Date: ____________  \n",
      "\n",
      "This contract will serve as the foundational agreement for the ongoing collaboration between Insurellm and TechDrive Insurance in optimizing their auto insurance offerings through the Carllm product.\n",
      "\n",
      "## Other HR Notes\n",
      "- Jordan K. Bishop has been an integral part of club initiatives, including the Insurellm Code Reviews and Feedback Group, providing peer support.\n",
      "- Active participant in the company's Diversity and Inclusion committee, promoting a positive work culture.\n",
      "- Jordan has expressed interest in professional development courses, particularly those focused on modern web technologies, which are being considered for sponsorship by Insurellm.\n",
      "- Engaged in a 6-month performance improvement plan as of August 2023, focusing on skill development and consistent performance monitoring. \n",
      "\n",
      "Jordan K. Bishop is a valued member of the Insurellm family, exhibiting a commitment to growth and development despite recent challenges.\n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **January 2017 - October 2018**: **Junior Data Engineer**  \n",
      "  * Maxine joined Insurellm as a Junior Data Engineer, focusing primarily on ETL processes and data integration tasks. She quickly learned Insurellm's data architecture, collaborating with other team members to streamline data workflows.  \n",
      "- **November 2018 - December 2020**: **Data Engineer**  \n",
      "  * In her new role, Maxine expanded her responsibilities to include designing comprehensive data models and improving data quality measures. Though she excelled in technical skills, communication issues with non-technical teams led to some project delays.  \n",
      "- **January 2021 - Present**: **Senior Data Engineer**  \n",
      "  * Maxine was promoted to Senior Data Engineer after successfully leading a pivotal project that improved data retrieval times by 30%. She now mentors junior engineers and is involved in strategic data initiatives, solidifying her position as a valued asset at Insurellm. She was recognized as Insurellm Innovator of the year in 2023, receiving the prestigious IIOTY 2023 award.\n",
      "\n",
      "## Other HR Notes\n",
      "- Jordan has shown an interest in continuing education, actively participating in company-sponsored sales webinars.  \n",
      "- Notable for involvement in the Insurellm volunteer program, assisting local charity events related to financial literacy.  \n",
      "- Employee wellness advocate, consistently promotes team bonding activities and stress-relief workshops.  \n",
      "- Plans to enroll in a course for advanced sales strategies in Q4 2023, aiming to further enhance his skills at Insurellm.\n",
      "\n",
      "## Other HR Notes\n",
      "- Alex Thomson is an active member of the Diversity and Inclusion committee at Insurellm and has participated in various community outreach programs.  \n",
      "- Alex has received external training on advanced CRM usage, which has subsequently improved team efficiency and productivity.\n",
      "- Continuous professional development through attending sales conventions and workshops, with plans to pursue certification in Sales Enablement in 2024.\n",
      "- Recognized by peers for promoting a supportive and high-energy team environment, often organizing team-building activities to enhance camaraderie within the SDR department. \n",
      "\n",
      "--- \n",
      "**Comment:** Alex Thomson is considered a cornerstone of Insurellm’s sales team and has a bright future within the organization.\n",
      "\n",
      "## Compensation History\n",
      "- **2020:** Base Salary: $80,000  \n",
      "- **2021:** Base Salary Increase to $90,000; Received a performance bonus of $5,000.  \n",
      "- **2022:** Base Salary Increase to $100,000; Performance bonus of $7,500 due to exceptional project outcomes.  \n",
      "- **2023:** Base Salary Increase to $115,000; Performance bonus of $10,000 for leading pivotal projects.\n",
      "\n",
      "## Other HR Notes\n",
      "- Participates regularly in Insurellm's Diversity & Inclusion initiatives, championing tech accessibility for underrepresented communities.\n",
      "- Completed several certifications in cloud architecture and DevOps, contributing to professional growth.\n",
      "- Plans for a professional development course in AI and machine learning to further enhance backend capabilities in Insurellm's offerings.\n",
      "- Acknowledged for volunteer efforts in local tech meetups, bringing seasoned engineers to mentor aspiring coders.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2020:** Exceeds Expectations  \n",
      "  Samantha Greene demonstrated exceptional organizational skills and contributed to a streamlined onboarding process, earning commendations from senior leadership.\n",
      "\n",
      "- **2021:** Meets Expectations  \n",
      "  While proficient in her new role, Samantha Greene struggled with time management during peak recruitment seasons, resulting in occasional missed deadlines. \n",
      "\n",
      "- **2022:** Below Expectations  \n",
      "  Samantha Greene faced challenges in balancing employee relations issues, thereby impacting her performance. Gaps in communication and follow-up led to a push for additional training.\n",
      "\n",
      "- **2023:** Meets Expectations  \n",
      "  After attending workshops focused on conflict resolution, Samantha Greene successfully improved her handling of employee grievances, though minor issues still arose in managing multitasking within projects.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2021:** First year at Insurellm; achieved 90% of monthly targets.  \n",
      "  - **Feedback:** Strong potential shown in lead generation; needs improvement in follow-up techniques.  \n",
      "- **2022:** Achieved 120% of targets; pioneered outreach strategies that increased customer engagement.  \n",
      "  - **Feedback:** Jordan's innovative approach contributed significantly to team success; recommended for leadership training.  \n",
      "- **2023:** Set to exceed annual targets by 30% in Q3; initiated successful partnerships that broadened market reach.  \n",
      "  - **Feedback:** Exceptional communicator; exemplifies the values of Insurellm and promotes team collaboration.\n",
      "\n",
      "## Compensation History\n",
      "- **2021-06:** Starting Salary: $50,000  \n",
      "- **2022-04:** Merit-based increase: $55,000 (based on performance review)  \n",
      "- **2023-06:** Performance bonus awarded: $5,000 (for exceeding goals as recognized in annual review)  \n",
      "- **2023-09:** Salary adjustment due to promotion to Senior SDR: $65,000\n",
      "\n",
      "- **2023:** Base Salary - $70,000  \n",
      "  Recognized for substantial improvement in employee relations management and contributions to company culture, leading to a well-deserved increase.\n",
      "\n",
      "## Other HR Notes\n",
      "- Samantha Greene has expressed interest in pursuing an HR certification (SHRM-CP) to further her career growth within Insurellm. \n",
      "- Participated in Insurellm's employee wellness program, promoting mental health resources among staff.\n",
      "- Actively volunteers with local nonprofits and encourages staff involvement in community outreach programs, enhancing Insurellm's corporate social responsibility initiatives. \n",
      "\n",
      "Samantha Greene is a valuable asset to Insurellm, continuously working on professional development and contributing to a supportive workplace culture.\n",
      "Human: Who received the prestigious IIOTY award in 2023?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Answer: Maxine received the prestigious IIOTY 2023 award.\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate what gets sent behind the scenes\n",
    "\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# ------------ new change ----------------- increaing number of chunks\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k':25})\n",
    "\n",
    "# Adding callbacks to our chain\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])\n",
    "\n",
    "# Adding our query question and getting traces back\n",
    "query = \"Who received the prestigious IIOTY award in 2023?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
